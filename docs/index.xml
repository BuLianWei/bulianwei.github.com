<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Abiu的博客</title>
    <link>https://github.com/BuLianWei/bulianwei.github.io/</link>
    <description>Recent content on Abiu的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Wed, 25 Dec 2019 11:50:00 +0000</lastBuildDate>
    
	<atom:link href="https://github.com/BuLianWei/bulianwei.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>SSL</title>
      <link>https://github.com/BuLianWei/bulianwei.github.io/notes/SSL/</link>
      <pubDate>Sat, 26 Dec 2020 09:06:39 +0800</pubDate>
      
      <guid>https://github.com/BuLianWei/bulianwei.github.io/notes/SSL/</guid>
      <description>生成服务端keystore（密钥和证书） keytool -keystore server.kestore.jks -alias server -validity 365 -storepass blw -kepass blw -genkey -dname * CH=CA,OU=eBay,O=eBay,L=SH,ST=SH,C=CN* 生成客户端keystore（密钥和证书） keytool -keystore client.kestore.jks -alias client -validity 365 -storepass blw -kepass blw -gankey -dname * CH=CA,OU=eBay,O=eBay,L=SH,ST=SH,C=CN* 将CA证书导入服务端truststore keytool -v -keystore server.truststore.jks -alias CARoot -import -file cat.crt -storepass blw 将CA证书导入客户端truststore keytool -v -keystore client.truststore.jks -alias CARoot -import -file cat.crt -storepass blw 导出服务端证书 keytool</description>
    </item>
    
    <item>
      <title>Go插件工具安装问题</title>
      <link>https://github.com/BuLianWei/bulianwei.github.io/notes/Go%E6%8F%92%E4%BB%B6%E5%B7%A5%E5%85%B7%E5%AE%89%E8%A3%85%E9%97%AE%E9%A2%98/</link>
      <pubDate>Sat, 26 Dec 2020 09:06:15 +0800</pubDate>
      
      <guid>https://github.com/BuLianWei/bulianwei.github.io/notes/Go%E6%8F%92%E4%BB%B6%E5%B7%A5%E5%85%B7%E5%AE%89%E8%A3%85%E9%97%AE%E9%A2%98/</guid>
      <description>Go插件工具安装问题 在Mac上在学习使用Go或者安装其他带有Go依赖的安装包时（比如git-lfs）可能会遇到Go插件工具安装问题下面我们就来解决一下这个问题（网上也有相关使用代理的情况，这里不再说明） 引发原因 mac 下的包管理工具brew 可以方便的安装工具包或者相应的软件应用，当使用</description>
    </item>
    
    <item>
      <title>自建CA证书认证</title>
      <link>https://github.com/BuLianWei/bulianwei.github.io/notes/%E8%87%AA%E5%BB%BACA%E8%AF%81%E4%B9%A6%E8%AE%A4%E8%AF%81/</link>
      <pubDate>Sat, 26 Dec 2020 09:05:11 +0800</pubDate>
      
      <guid>https://github.com/BuLianWei/bulianwei.github.io/notes/%E8%87%AA%E5%BB%BACA%E8%AF%81%E4%B9%A6%E8%AE%A4%E8%AF%81/</guid>
      <description>自建CA证书认证 CA证书认证通常包含三部分，CA认证服务器、业务服务器、客户端，也可以简单分成两部分CA/业务服务器，和客户端 CA服务器 生成私钥(pem) openssl genrsa -out cakey.pem -des 2048 gen:生成 rsa:加密算法 out:输出 des:秘钥加密口令(可加可不加) 2048:秘钥生成长度(2048 bits</description>
    </item>
    
    <item>
      <title>Kubernetes安装</title>
      <link>https://github.com/BuLianWei/bulianwei.github.io/post/Kubernetes%E5%AE%89%E8%A3%85/</link>
      <pubDate>Fri, 25 Dec 2020 16:24:58 +0800</pubDate>
      
      <guid>https://github.com/BuLianWei/bulianwei.github.io/post/Kubernetes%E5%AE%89%E8%A3%85/</guid>
      <description>Kubernetes 安装 本次安装环境 Centos 7 本次使用阿里镜像源 https://developer.aliyun.com/mirror 准备 Yum repo 镜像库（master，node） 从阿里镜像源找到 kubernetes 从目录里面找到 yum repo 地址 https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ 从目录里面找到 key 验证地址 https://mirrors.aliyun.com/kubernetes/yum/doc/ 右键复制https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key</description>
    </item>
    
    <item>
      <title>Docekr安装</title>
      <link>https://github.com/BuLianWei/bulianwei.github.io/post/Docekr%E5%AE%89%E8%A3%85/</link>
      <pubDate>Fri, 25 Dec 2020 08:22:55 +0800</pubDate>
      
      <guid>https://github.com/BuLianWei/bulianwei.github.io/post/Docekr%E5%AE%89%E8%A3%85/</guid>
      <description>安装Docker 本次安装在 CentOS 7上使用 Yum 安装 本次使用阿里镜像源安装 阿里镜像地址 https://developer.aliyun.com/mirror/ 准备环境 查找 docker-ce repo 库 在目录https://mirrors.aliyun.com/docker-ce/linux/centos/下找到docker-ce.repo 右键复制地址链接 下载 docker-ce repo 库 wget -O /etc/yum.repos.d/docker-ce.repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 或 curl -o /etc/yum.repos.d/docker-ce.repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</description>
    </item>
    
    <item>
      <title>Trouble</title>
      <link>https://github.com/BuLianWei/bulianwei.github.io/post/Trouble/</link>
      <pubDate>Mon, 16 Nov 2020 22:12:47 +0800</pubDate>
      
      <guid>https://github.com/BuLianWei/bulianwei.github.io/post/Trouble/</guid>
      <description>Could not transfer artifact org.apache.flink:flink-runtime_2.11:jar:1.10.0 from/to central (https://repo.maven.apache.org/maven2): GET request of: org/apache/flink/flink-runtime_2.11/1.10.0/flink-runtime_2.11-1.10.0.jar from central failed: Premature end of Content-Length delimited message body (expected: 12,008,735; received: 2,379,621) -&amp;gt; [Help 1] 由于之前从网上加载依赖包没有加载完全，导致本地库中的包不完全，所以没有办法重新加载依赖。可以直接找到相应的包目录将目录删除，然后从新下载。 本文中直接删除.m2/repository/org/apache/flink/fli</description>
    </item>
    
    <item>
      <title>Flink</title>
      <link>https://github.com/BuLianWei/bulianwei.github.io/post/Flink/</link>
      <pubDate>Wed, 19 Aug 2020 20:50:34 +0800</pubDate>
      
      <guid>https://github.com/BuLianWei/bulianwei.github.io/post/Flink/</guid>
      <description>Flink 部署 On Yarn yarn-session 开启session yarn-session.sh -jm 1024m -tm 4096m 在session上提交作业 flink run -m yarn-cluster -p 4 -yjm 1024m -ytm 4096m ./examples/batch/WordCount.jar 关闭session echo &amp;ldquo;stop&amp;rdquo; | ./bin/yarn-session.sh -id -D 使用-D将要设置的参数进行设置（-Dtaskmanager.memory.network.min=536346624） -d,&amp;ndash;detached 开启分离模式（session启动后clie</description>
    </item>
    
    <item>
      <title>Kafka</title>
      <link>https://github.com/BuLianWei/bulianwei.github.io/notes/Kafka/</link>
      <pubDate>Mon, 13 Jan 2020 15:22:21 +0000</pubDate>
      
      <guid>https://github.com/BuLianWei/bulianwei.github.io/notes/Kafka/</guid>
      <description>Kafka 一个分区内的数据才能保证幂等性和有序性 架构 名次解释 Broker：Kafka服务器 Producer：生产者，生产消息 Consumer：消费者，消费数据 Consumer Group：消费者组，某一个分区只能被同一个消费者组内的一个消费者消费 Topic：消息主题。逻辑概念 Partition：消息分区</description>
    </item>
    
    <item>
      <title>Redis</title>
      <link>https://github.com/BuLianWei/bulianwei.github.io/notes/Redis/</link>
      <pubDate>Thu, 26 Dec 2019 23:50:21 +0000</pubDate>
      
      <guid>https://github.com/BuLianWei/bulianwei.github.io/notes/Redis/</guid>
      <description>Redis（Remote Dictionary Server） Redis 运行快速的原因 完全基于内存操作 数据结构简单，数据操作也简单 使用多路I/O复用模型 数据类型 String 单条操作 增：set key value 查：get key 删：del key 多条操作 增：mset key value [key1 value1] 查：mget key [key1] 其他命令 strlen key //获取字符串长度 append key value //有则追加，无则新建</description>
    </item>
    
    <item>
      <title>个人简历</title>
      <link>https://github.com/BuLianWei/bulianwei.github.io/about/</link>
      <pubDate>Wed, 25 Dec 2019 11:50:00 +0000</pubDate>
      
      <guid>https://github.com/BuLianWei/bulianwei.github.io/about/</guid>
      <description>自我评价 大数据平台从 0 到 1的构建，数据仓库数据架构的设计，数据模型规划及实施，元数据管理建设、TB级别离线数据处理和优化等经验 利用层析分析构建模型，OLP标签目录体系构建标签 教育背景 2012.9 ～ 2015.7 山东劳动职业技术学院 大专 软件工程 工作经历 2020/4 ~ 2020/7 杭州数澜科技有限公司 大数据开发 2017/6 ~ 2019/12 轻图信息技</description>
    </item>
    
    <item>
      <title>Hello World</title>
      <link>https://github.com/BuLianWei/bulianwei.github.io/notes/hello-world/</link>
      <pubDate>Wed, 12 Sep 2018 22:25:00 +0000</pubDate>
      
      <guid>https://github.com/BuLianWei/bulianwei.github.io/notes/hello-world/</guid>
      <description>Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.
Quick Start Create a new post $ hexo new &amp;#34;My New Post&amp;#34; More info: Writing
Run server $ hexo server More info: Server
Generate static files $ hexo generate More info: Generating
Deploy to remote sites $ hexo deploy More info: Deployment</description>
    </item>
    
    <item>
      <title>BigData</title>
      <link>https://github.com/BuLianWei/bulianwei.github.io/notes/Bigdata/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://github.com/BuLianWei/bulianwei.github.io/notes/Bigdata/</guid>
      <description>Bigdata 1. Hadoop 1.hdfs集群：负责文件读写 2.yarn集群：负责为mapredece程序分配运算硬件资源 Hadoop配置： 1.core-site.xml：fs.DefaultFS hadoop.tmp.dir 2.hadoop.env.sh: JAVA_HOME 3.mapred-site.xml: mapreduce.framework.name 4.hdfs-site.xml: dfs.replication 5.yarn-site.xml: yarn.resourcemanager.hostname yarn.nodemanager.aux-services slaves：自动化脚本使用的配置文件 修改Linux启动等待时间 vi /etc/fstab mkdir -p /aa/bb/cc 可以直接建立a</description>
    </item>
    
    <item>
      <title>Docker</title>
      <link>https://github.com/BuLianWei/bulianwei.github.io/notes/Docker/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://github.com/BuLianWei/bulianwei.github.io/notes/Docker/</guid>
      <description>Docker 命令 镜像 docker images //列出本地镜像 -a //列出本地所有镜像 -q //只显示镜像ID &amp;ndash;digests //显示镜像的摘要信息 &amp;ndash;no-trunc //显示完整的镜像信息 docker search //查找镜像 &amp;ndash;no-trunc //显示完整的镜像描述 -s //列出收藏数不小于制定值的镜像 &amp;ndash;automated //只列出automated build 类型的镜像 docker pull //下载镜像 docker rmi //删除镜像 -f //强制删</description>
    </item>
    
    <item>
      <title>Flink</title>
      <link>https://github.com/BuLianWei/bulianwei.github.io/notes/Flink/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://github.com/BuLianWei/bulianwei.github.io/notes/Flink/</guid>
      <description>Flink Application 启动：flink run -c mainclasspath jarpath 取消：flink cancel jobid 停止：flink stop jobid Job Task job中的一个阶段就是一个task，一个task包括链条连接的多个subtask，一个task运行在一个线程里面，task平分slot里面的内存资源共享slot里面的cpu资源 SubTask flink job中最小执行单元 算子 Source 使</description>
    </item>
    
    <item>
      <title>Flink-Trouble</title>
      <link>https://github.com/BuLianWei/bulianwei.github.io/notes/Flink-Trouble/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://github.com/BuLianWei/bulianwei.github.io/notes/Flink-Trouble/</guid>
      <description>Flink-Trouble 1. 处理时间窗口数据时未添加窗口或者设置处理的时间类型 错误现象 Caused by: java.lang.RuntimeException: Record has Long.MIN_VALUE timestamp (= no timestamp marker). Is the time characteristic set to &#39;ProcessingTime&#39;, or did you forget to call &#39;DataStream.assignTimestampsAndWatermarks(...)&#39;? 解决方案 assignTimestampsAndWatermarks env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime); 2. 程序重写(删除算子)导致使用savepoint数据快照无法恢复启动 错误现象 Failed to rollback to checkpoint/savepoint file:/Users/bulianwei/workspace/project/idea/flink_demo/data/test/savepoint-18c72f-803ce50127dc. Cannot map checkpoint/savepoint state for operator c27dcf7b54ef6bfd6cff02ca8870b681 to the new program, because the operator is not available in the new program. If you want to allow to skip this, you can set the --allowNonRestoredState</description>
    </item>
    
    <item>
      <title>Git&amp;GitHub</title>
      <link>https://github.com/BuLianWei/bulianwei.github.io/notes/GitGitHub/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://github.com/BuLianWei/bulianwei.github.io/notes/GitGitHub/</guid>
      <description>Git &amp;amp; GitHub Git init clone add 将变化提交到staging area（暂存区） git add filename 添加file 到staging area git add . 提交新文件(new)和被修改(modified)文件，不包括被删除(deleted)文件 git add -u (git add &amp;ndash;update) 提交被修改(modified)和被删除(deleted)文件，不包括新文件(ne</description>
    </item>
    
    <item>
      <title>Golang</title>
      <link>https://github.com/BuLianWei/bulianwei.github.io/notes/Golang/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://github.com/BuLianWei/bulianwei.github.io/notes/Golang/</guid>
      <description>Golang 数据类型 数值类型 bool byte byte = uint8 int 有符号类型：int8，int16，int32，int64 无符号类型：uint8，uint16，uint32，uint64 rune = int32 float float16，float32 string 数组 数组类型声明赋值方式 1 var arr [3]int arr[0] = 1 arr[1] = 2 arr[2] = 3 2 var arr =[3]int{1,2,3} 3 var arr =[...]int{1,2,3} 4 arr :=[3]int{1,2,3} 5 arr :=[...]int{1,2,3} 不管是使用&amp;</description>
    </item>
    
    <item>
      <title>Hive</title>
      <link>https://github.com/BuLianWei/bulianwei.github.io/notes/Hive/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://github.com/BuLianWei/bulianwei.github.io/notes/Hive/</guid>
      <description>表的数据加载 insert load 创建分区表（外表） 数据导出 hdfs dfs -get filename hdfs dfs -text filename //查看 insert overwrite 【local】 directory &amp;lsquo;filename&amp;rsquo; 【row format delimited fields terminated by &amp;lsquo;\t&amp;rsquo;】 select col， col1 from tablename //local 与 row。。 只能在导出到本地时使用 Shell 命令加管道：hive -f/e | sed/awk/gred &amp;gt;filename sqoop 动态分区 设置 set hive.exec.dynamic.partition=true //设置使用动态分区 设置 set hive.exec.dynamic.partition.mode=nonstrict //使用无限</description>
    </item>
    
    <item>
      <title>Java</title>
      <link>https://github.com/BuLianWei/bulianwei.github.io/notes/Java/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://github.com/BuLianWei/bulianwei.github.io/notes/Java/</guid>
      <description>Java基础知识清单 JVM JVM架构 Class file 有特定的文件标示（cafe babe），由类加载器加载进JVM方法区 在加载类时：静态块（只会加载一次）&amp;gt;构造块&amp;gt;构造方法 类加载器（ClassLoader） 实现通过类的全限定名（java/lang/String）获取该类的二进制字节流的</description>
    </item>
    
    <item>
      <title>Linux</title>
      <link>https://github.com/BuLianWei/bulianwei.github.io/notes/Linux/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://github.com/BuLianWei/bulianwei.github.io/notes/Linux/</guid>
      <description>#Linux 1. 挂载 mount -t iso9660 -o ro /dev/cdrom /mnt/cdrom //将文件类型为iso9660的文件 以只读（ro）方式从 /dev/cdrom 挂载到/mnt/cdrom 2. 设置开机自动挂载 vi /etc/fstab /dev/cdrom /mnt/cdrom iso9660 defaults 0 0 3. 关闭防火墙 chkconfig iptables --list chkconfig iptables off //重启时也自动关闭 4. 设置yum本地源 cd /etc/yum.repos.d/ 修改baseurl=file:///或http:// 5. 将自己的包配置成yu</description>
    </item>
    
    <item>
      <title>Scala</title>
      <link>https://github.com/BuLianWei/bulianwei.github.io/notes/Scala/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://github.com/BuLianWei/bulianwei.github.io/notes/Scala/</guid>
      <description>Scala 1. 半生类和半生对象 //半生类 class A{ def apply()={ } } //半生对象 object A{ def apply()={ } } val a=A() //调用的是object.apply val a1=new A() al() //调用的是class.apply //类名() object.apply //对象名() class.apply 最佳实践是在object的apply里面 new Class 2. 尾递归求和 def sum(nums:Int*)={ if(nums==0){ 0 }else{ nums.head+sum(nums.tail:_*) } } 3. Range to // 闭区间 until //左闭右开 Range</description>
    </item>
    
    <item>
      <title>Spark</title>
      <link>https://github.com/BuLianWei/bulianwei.github.io/notes/Spark/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://github.com/BuLianWei/bulianwei.github.io/notes/Spark/</guid>
      <description>Spark 编码 1. map 和 mapPartitions map是对rdd中的每一个元素进行操作； mapPartitions则是对rdd中的每个分区的迭代器进行操作 MapPartitions的优点： 如果是普通的map，比如一个partition中有1万条数据。ok，那么你的function要执行和计算1万次。 使用MapPa</description>
    </item>
    
  </channel>
</rss>